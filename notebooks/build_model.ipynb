{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import math\n",
    "\n",
    "import torch \n",
    "from torch import nn, Tensor\n",
    "from torch.nn import functional as F "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 120, 6])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 32\n",
    "ft_dims = 6\n",
    "seq_len = 120\n",
    "sample_input = torch.randn((bs, seq_len, ft_dims))\n",
    "sample_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 120, 128])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use of linear projection layer\n",
    "d_model = 128\n",
    "denseL = nn.Linear(ft_dims, d_model)\n",
    "\n",
    "sample_out = denseL(sample_input)\n",
    "sample_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 120, 128])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use of Attention layer \n",
    "n_heads = 8\n",
    "inter_ft = 128\n",
    "attnL = nn.TransformerEncoderLayer(d_model, n_heads, inter_ft)\n",
    "\n",
    "sample_out = attnL(sample_out)\n",
    "sample_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerEncoderLayer(\n",
       "  (self_attn): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout1): Dropout(p=0.1, inplace=False)\n",
       "  (dropout2): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attnL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relative global attention based transformer encoder implementation\n",
    "class RelativeGlobalAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, max_len=1024, dropout=0.1):\n",
    "        super().__init__()\n",
    "        d_head, remainder = divmod(d_model, num_heads)\n",
    "        if remainder:\n",
    "            raise ValueError(\n",
    "                \"incompatible `d_model` and `num_heads`\"\n",
    "            )\n",
    "        self.max_len = max_len\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.key = nn.Linear(d_model, d_model)\n",
    "        self.value = nn.Linear(d_model, d_model)\n",
    "        self.query = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.Er = nn.Parameter(torch.randn(max_len, d_head))\n",
    "        self.register_buffer(\n",
    "            \"mask\", \n",
    "            torch.tril(torch.ones(max_len, max_len))\n",
    "            .unsqueeze(0).unsqueeze(0)\n",
    "        )\n",
    "        # self.mask.shape = (1, 1, max_len, max_len)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x.shape == (batch_size, seq_len, d_model)\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        \n",
    "        if seq_len > self.max_len:\n",
    "            raise ValueError(\n",
    "                \"sequence length exceeds model capacity\"\n",
    "            )\n",
    "        \n",
    "        k_t = self.key(x).reshape(batch_size, seq_len, self.num_heads, -1).permute(0, 2, 3, 1)\n",
    "        # k_t.shape = (batch_size, num_heads, d_head, seq_len)\n",
    "        v = self.value(x).reshape(batch_size, seq_len, self.num_heads, -1).transpose(1, 2)\n",
    "        q = self.query(x).reshape(batch_size, seq_len, self.num_heads, -1).transpose(1, 2)\n",
    "        # shape = (batch_size, num_heads, seq_len, d_head)\n",
    "        \n",
    "        start = self.max_len - seq_len\n",
    "        Er_t = self.Er[start:, :].transpose(0, 1)\n",
    "        # Er_t.shape = (d_head, seq_len)\n",
    "        QEr = torch.matmul(q, Er_t)\n",
    "        # QEr.shape = (batch_size, num_heads, seq_len, seq_len)\n",
    "        Srel = self.skew(QEr)\n",
    "        # Srel.shape = (batch_size, num_heads, seq_len, seq_len)\n",
    "        \n",
    "        QK_t = torch.matmul(q, k_t)\n",
    "        # QK_t.shape = (batch_size, num_heads, seq_len, seq_len)\n",
    "        attn = (QK_t + Srel) / math.sqrt(q.size(-1))\n",
    "        mask = self.mask[:, :, :seq_len, :seq_len]\n",
    "        # mask.shape = (1, 1, seq_len, seq_len)\n",
    "        attn = attn.masked_fill(mask == 0, float(\"-inf\"))\n",
    "        # attn.shape = (batch_size, num_heads, seq_len, seq_len)\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        out = torch.matmul(attn, v)\n",
    "        # out.shape = (batch_size, num_heads, seq_len, d_head)\n",
    "        out = out.transpose(1, 2)\n",
    "        # out.shape == (batch_size, seq_len, num_heads, d_head)\n",
    "        out = out.reshape(batch_size, seq_len, -1)\n",
    "        # out.shape == (batch_size, seq_len, d_model)\n",
    "        return self.dropout(out)\n",
    "        \n",
    "    \n",
    "    def skew(self, QEr):\n",
    "        # QEr.shape = (batch_size, num_heads, seq_len, seq_len)\n",
    "        padded = F.pad(QEr, (1, 0))\n",
    "        # padded.shape = (batch_size, num_heads, seq_len, 1 + seq_len)\n",
    "        batch_size, num_heads, num_rows, num_cols = padded.shape\n",
    "        reshaped = padded.reshape(batch_size, num_heads, num_cols, num_rows)\n",
    "        # reshaped.size = (batch_size, num_heads, 1 + seq_len, seq_len)\n",
    "        Srel = reshaped[:, :, 1:, :]\n",
    "        # Srel.shape = (batch_size, num_heads, seq_len, seq_len)\n",
    "        return Srel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 120, 128])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test relative Glob. Attn.\n",
    "relAttnL = RelativeGlobalAttention(d_model, n_heads, seq_len)\n",
    "\n",
    "sample_input1 = denseL(sample_input)\n",
    "sample_out = relAttnL(sample_input1)\n",
    "sample_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build E2E ZSL HAR Model\n",
    "\n",
    "class ZSLHARNet(nn.Module):\n",
    "    def __init__(self, in_ft, d_model, num_heads, ft_size, attr_size, max_len=1024, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.in_ft = in_ft\n",
    "        self.max_len = max_len\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.ft_size = ft_size # semantic space size <-> output feature space size\n",
    "        self.attr_size = attr_size # intermediate attribute space size \n",
    "\n",
    "        # custom sample layer configuration\n",
    "        # Dense layer for feature projection\n",
    "        self.DenseL = nn.Linear(in_ft, d_model)\n",
    "        # attention encoder <-> global relative attention used here\n",
    "        self.AttnL = RelativeGlobalAttention(d_model, num_heads, max_len)\n",
    "        # positional encoding concat <-> LSTM \n",
    "        self.lstmL = nn.LSTM(input_size=d_model, hidden_size=ft_size, batch_first=True)\n",
    "        # SAE submodule\n",
    "        self.EncDenseL = nn.Linear(in_features=ft_size, out_features=attr_size, bias=False)\n",
    "        self.DecDenseL = nn.Linear(in_features=attr_size, out_features=ft_dims, bias=False)\n",
    "        # override weights\n",
    "        del self.EncDenseL.weight\n",
    "        del self.DecDenseL.weight\n",
    "        # define shared weights\n",
    "        self.TransMet = nn.Parameter(torch.randn(attr_size, ft_size))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.DenseL(x)\n",
    "        out = self.AttnL(out)\n",
    "        lstm_out, hidden = self.lstmL(out)\n",
    "        # SAE Operation\n",
    "        self.EncDenseL.weight = self.TransMet\n",
    "        self.DecDenseL.weight = self.TransMet.T \n",
    "        attr_out = self.EncDenseL(lstm_out[:, -1, :])\n",
    "        ft_out = self.DecDenseL(attr_out)\n",
    "        return attr_out, ft_out\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ZSLHARNet(in_ft=6, d_model=128, num_heads=8, ft_size=64, attr_size=16, max_len=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 16]) torch.Size([32, 64])\n"
     ]
    }
   ],
   "source": [
    "sample_input = torch.randn((bs, 120, 6))\n",
    "\n",
    "attr_out, feat_out = model(sample_input)\n",
    "print(attr_out.shape, feat_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9738e-01,  1.3880e-01, -2.3393e-01, -1.4038e-01, -2.6661e-01,\n",
       "          3.4279e-01, -2.5056e-02, -4.5227e-01, -4.0780e-01,  1.6693e-01,\n",
       "         -6.1354e-02,  5.2765e-01, -2.0932e-01,  6.7647e-01, -2.9521e-01,\n",
       "         -1.8451e-02],\n",
       "        [-7.9600e-02,  1.4353e-01, -2.1818e-01, -1.2940e-01, -2.6362e-01,\n",
       "          4.5588e-01, -2.4781e-01, -6.1644e-01, -6.3781e-01,  3.5662e-01,\n",
       "          2.6989e-02,  4.4249e-01, -1.2734e-01,  3.8886e-01, -1.3834e-01,\n",
       "         -1.6093e-01],\n",
       "        [ 1.7725e-01,  9.2594e-02, -1.2674e-01, -2.9718e-01, -1.7856e-01,\n",
       "          8.9125e-01, -1.8151e-01, -5.9856e-01, -4.5926e-01, -3.2906e-01,\n",
       "         -1.5519e-01,  5.6246e-01, -5.2584e-01,  6.3432e-01,  1.2672e-01,\n",
       "          1.8171e-02],\n",
       "        [-1.8424e-01,  2.0375e-01, -2.9534e-01, -2.5335e-01, -2.3889e-03,\n",
       "          2.9360e-01, -8.8648e-02, -5.7559e-01, -6.2367e-01,  2.3156e-01,\n",
       "         -3.4893e-01,  1.1374e-01, -8.3828e-03,  7.6266e-01, -4.7523e-01,\n",
       "         -3.7745e-01],\n",
       "        [ 3.4628e-01,  8.7775e-02, -4.1841e-01, -4.9109e-01, -1.1121e-01,\n",
       "          5.5190e-01,  1.6378e-01, -5.4468e-01, -6.7273e-01, -1.3920e-01,\n",
       "         -2.4627e-01,  5.6810e-01, -3.2862e-01,  7.2402e-01,  4.5886e-02,\n",
       "         -2.1147e-01],\n",
       "        [ 2.9631e-01,  7.7240e-02, -1.2257e-01, -1.9831e-01, -3.1429e-01,\n",
       "          5.6321e-01, -1.0023e-01, -4.8107e-01, -5.1229e-01, -1.0074e-01,\n",
       "         -1.2442e-01,  6.7835e-01, -3.0662e-01,  5.4369e-01, -8.4218e-02,\n",
       "          1.1387e-01],\n",
       "        [-1.6267e-01,  3.4951e-01, -2.5630e-01, -6.7911e-02, -1.8490e-01,\n",
       "          4.3903e-01, -2.4118e-01, -5.0063e-01, -5.4381e-01,  3.0212e-01,\n",
       "          1.9523e-01,  5.8529e-01, -2.0069e-01,  5.9180e-01, -4.4047e-01,\n",
       "         -1.3157e-01],\n",
       "        [-1.1543e-01,  1.8601e-01, -3.1015e-01, -1.2551e-01, -1.0991e-01,\n",
       "          4.6109e-01, -1.3306e-01, -5.0303e-01, -5.8947e-01,  9.4259e-02,\n",
       "         -3.3730e-01,  4.8554e-01, -2.4299e-01,  6.4047e-01, -1.8570e-01,\n",
       "         -1.9839e-01],\n",
       "        [ 1.3928e-01,  4.8193e-02, -3.2697e-01, -2.6283e-01, -2.7719e-01,\n",
       "          5.4579e-01, -2.5560e-01, -4.2277e-01, -4.6314e-01,  1.1210e-01,\n",
       "         -2.5828e-01,  6.3817e-01, -1.1513e-01,  5.3094e-01, -2.4860e-01,\n",
       "          4.2141e-02],\n",
       "        [ 1.2471e-01, -1.7902e-02, -4.9172e-01,  1.4008e-02,  9.4411e-03,\n",
       "          4.6463e-01, -1.4152e-01, -3.1207e-01, -5.4418e-01,  4.9623e-02,\n",
       "         -2.4671e-01,  3.4030e-01, -2.0642e-01,  6.0808e-01, -1.7377e-01,\n",
       "         -2.8074e-02],\n",
       "        [ 1.1845e-01,  2.2328e-01, -3.0955e-01, -3.2579e-01,  5.8858e-02,\n",
       "          2.5447e-01,  1.5798e-01, -5.0344e-01, -7.2482e-01,  3.4178e-01,\n",
       "         -3.7786e-01,  2.9986e-01, -1.9994e-01,  8.0541e-01, -1.5364e-01,\n",
       "         -4.4718e-01],\n",
       "        [ 2.5593e-01,  9.6298e-02, -3.7306e-01, -2.9874e-01, -1.0712e-01,\n",
       "          3.2617e-01, -4.6411e-03, -5.0419e-01, -6.3708e-01,  2.8219e-01,\n",
       "          9.5082e-02,  5.6418e-01, -1.3398e-01,  6.0089e-01, -1.5869e-01,\n",
       "         -1.9538e-01],\n",
       "        [ 2.1441e-01,  8.1740e-02, -3.1933e-01, -1.9400e-01, -2.3518e-02,\n",
       "          4.0715e-01,  6.5789e-04, -4.1317e-01, -4.0640e-01,  1.2489e-01,\n",
       "         -3.3518e-01,  3.5296e-01, -7.8434e-02,  7.2205e-01, -2.8324e-01,\n",
       "          2.4673e-03],\n",
       "        [-2.4265e-01,  1.6845e-02, -1.6040e-02,  1.7163e-02, -3.3198e-01,\n",
       "          2.7886e-01, -7.7706e-02, -7.1674e-01, -4.4209e-01,  1.8564e-01,\n",
       "         -4.0269e-01,  3.6787e-01, -1.7634e-01,  4.9598e-01, -2.0371e-01,\n",
       "          9.6643e-02],\n",
       "        [ 1.3946e-01,  2.2675e-01, -4.6890e-01, -4.0825e-01, -1.2442e-01,\n",
       "          3.9117e-01,  8.3959e-03, -3.0992e-01, -7.1256e-01,  1.8397e-01,\n",
       "          6.1145e-02,  4.7299e-01, -3.5044e-01,  4.8786e-01, -2.1818e-01,\n",
       "         -1.6027e-01],\n",
       "        [ 7.2093e-02,  1.5752e-01, -3.8501e-01, -4.1711e-01, -1.5459e-01,\n",
       "          5.1904e-01, -4.4410e-02, -7.2009e-01, -5.1241e-01,  4.1341e-02,\n",
       "         -3.4360e-01,  5.4283e-01, -1.5782e-01,  4.6249e-01,  3.9497e-02,\n",
       "         -9.5746e-02],\n",
       "        [-5.0477e-02,  9.4170e-02, -3.0425e-01, -2.3544e-01, -1.4638e-01,\n",
       "          4.0270e-01, -1.1542e-01, -6.8694e-01, -6.8328e-01,  4.2965e-02,\n",
       "          8.1490e-03,  6.1373e-01, -2.9349e-01,  3.4049e-01, -1.8077e-01,\n",
       "         -9.5737e-02],\n",
       "        [ 3.1404e-01,  1.4936e-01, -3.5224e-01, -2.3465e-01, -1.4715e-01,\n",
       "          5.8719e-01, -4.6368e-02, -4.5802e-01, -4.6090e-01, -2.6451e-02,\n",
       "         -2.7880e-01,  5.1910e-01, -1.8418e-01,  9.2053e-01, -1.5686e-01,\n",
       "         -1.6816e-01],\n",
       "        [ 4.4938e-02,  8.4141e-02, -3.6610e-01, -2.9554e-01, -1.0677e-01,\n",
       "          3.5756e-01, -7.8740e-02, -4.6152e-01, -4.2627e-01,  2.6002e-01,\n",
       "         -3.5228e-01,  5.0920e-01, -1.5590e-01,  6.7498e-01, -3.2510e-01,\n",
       "         -1.0301e-01],\n",
       "        [ 3.6539e-01,  5.7803e-02, -3.1864e-01, -2.7937e-01, -3.7932e-01,\n",
       "          5.0523e-01, -1.5115e-01, -4.9796e-01, -3.5688e-01, -3.0276e-02,\n",
       "          1.6496e-01,  7.1153e-01, -8.9098e-02,  4.1338e-01, -1.2946e-02,\n",
       "          1.7788e-01],\n",
       "        [ 2.5452e-01,  4.1485e-02, -1.6059e-01, -2.0579e-01, -2.8182e-01,\n",
       "          4.1829e-01, -1.4767e-01, -5.0985e-01, -5.1588e-01,  4.3106e-01,\n",
       "          9.1977e-03,  4.5430e-01,  1.9722e-02,  4.3035e-01, -1.0693e-01,\n",
       "          3.7503e-02],\n",
       "        [ 2.6192e-01,  1.4504e-01, -3.4100e-01, -2.8627e-01, -2.7411e-01,\n",
       "          3.7604e-01, -1.3529e-01, -1.7498e-01, -5.6386e-01,  3.3920e-01,\n",
       "          2.1091e-01,  6.5765e-01, -1.4413e-01,  5.9318e-01, -3.0777e-01,\n",
       "         -1.3474e-04],\n",
       "        [ 1.1662e-01,  1.1774e-01, -2.1612e-01, -2.9993e-01, -2.2421e-01,\n",
       "          3.1043e-01,  1.3149e-01, -6.9555e-01, -7.8568e-01,  1.9202e-01,\n",
       "         -2.3017e-01,  5.4827e-01, -7.1935e-02,  7.0901e-01, -2.8803e-01,\n",
       "         -2.1713e-01],\n",
       "        [-2.6241e-01,  8.6388e-02, -1.4817e-01, -2.3246e-01, -1.7317e-01,\n",
       "          2.2240e-01, -1.6739e-01, -6.4946e-01, -5.0211e-01,  3.6960e-01,\n",
       "         -7.9360e-02,  4.2091e-01, -2.4964e-01,  2.7553e-01, -1.1943e-01,\n",
       "          2.2409e-02],\n",
       "        [-5.3380e-02,  2.3928e-01, -3.9426e-01, -4.1403e-01,  7.4661e-03,\n",
       "          3.7195e-01,  2.4221e-02, -6.7701e-01, -8.3846e-01,  1.4649e-01,\n",
       "          4.7254e-02,  4.8459e-01, -2.8308e-01,  4.6847e-01, -8.0702e-03,\n",
       "         -2.3185e-01],\n",
       "        [ 7.6516e-02,  9.7495e-02, -1.4735e-01, -3.4191e-01, -1.1908e-01,\n",
       "          4.6381e-01,  1.2382e-01, -7.3189e-01, -6.3219e-01, -3.3641e-02,\n",
       "         -2.3442e-01,  6.3219e-01, -3.2435e-01,  5.1687e-01,  3.1596e-02,\n",
       "         -2.0109e-01],\n",
       "        [-8.9140e-02,  2.3326e-01, -2.4089e-01, -3.6432e-01,  1.0128e-01,\n",
       "          5.8128e-01, -9.0175e-02, -7.4461e-01, -5.1671e-01,  9.7400e-02,\n",
       "         -4.6480e-01,  5.0203e-01, -2.1647e-01,  5.9660e-01, -2.3830e-02,\n",
       "         -2.4690e-01],\n",
       "        [ 1.0590e-01,  1.0858e-01, -4.3759e-01, -1.9568e-01, -5.0507e-02,\n",
       "          5.6679e-01, -4.5870e-02, -4.3627e-01, -7.0714e-01,  2.0534e-02,\n",
       "         -5.0494e-02,  4.5841e-01, -2.4806e-01,  6.1917e-01, -4.4701e-02,\n",
       "         -2.8850e-01],\n",
       "        [ 1.3478e-02,  1.1605e-01, -3.3858e-01, -3.2868e-01,  8.4638e-02,\n",
       "          4.2673e-01,  1.3730e-01, -7.7897e-01, -5.4839e-01, -1.4352e-02,\n",
       "         -4.9691e-01,  4.7868e-01, -2.9163e-01,  5.1092e-01,  3.3038e-02,\n",
       "         -2.6520e-01],\n",
       "        [ 2.7775e-02,  2.3262e-01, -4.3057e-01, -1.3511e-01, -2.0091e-01,\n",
       "          2.5328e-01, -1.0842e-01, -1.4415e-01, -6.3989e-01,  2.9119e-01,\n",
       "          1.7956e-01,  6.5913e-01, -2.6319e-01,  6.1564e-01, -1.3224e-01,\n",
       "         -1.5114e-01],\n",
       "        [ 9.4825e-03,  1.6215e-01, -2.8642e-01, -1.7621e-01, -1.2834e-01,\n",
       "          2.5176e-01, -7.4740e-02, -4.5858e-01, -5.3254e-01,  1.7340e-01,\n",
       "          1.5662e-01,  6.2806e-01, -2.9846e-01,  5.2160e-01, -3.0203e-01,\n",
       "          9.0346e-02],\n",
       "        [ 3.2287e-01,  2.2240e-01, -2.4243e-01, -3.2310e-01, -6.7275e-02,\n",
       "          6.1527e-01, -1.4778e-01, -3.8224e-01, -3.2589e-01, -1.7023e-01,\n",
       "         -3.4348e-01,  4.0201e-01, -3.3629e-01,  8.9301e-01, -1.9252e-01,\n",
       "         -1.5626e-01]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mvts_trans')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ccc35149ad8fa032444ebff1245e6ef176e6c1ce3af8dec48e3374f21a6b0f27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
