{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Fvq_SNT4wtrt"},"outputs":[],"source":["import os \n","import random\n","import numpy as np\n","from tqdm import tqdm\n","\n","import torch \n","from torch import nn \n","from torch import optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","import random\n","import copy\n","import seaborn as sns\n","from pylab import rcParams\n","import matplotlib.pyplot as plt\n","import shutil\n","\n","%matplotlib inline\n","%config InlineBackend.figure_format='retina'\n","\n","sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n","\n","HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n","\n","sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n","\n","rcParams['figure.figsize'] = 12, 8"]},{"cell_type":"code","source":["root_dir = \"/content\"\n","main_dir = \"/content/drive/MyDrive/22_FYP42 - Zero-shot Explainable HAR\"\n","data_dir = os.path.join(main_dir,\"Datasets\",\"skeleton_out\")\n","refined_data = os.path.join(main_dir,\"Datasets\",\"sequence_data\")\n","class_names = os.listdir(data_dir)\n","train_ratio = 0.7\n","val_ratio = 0.15\n","test_ratio = 1-train_ratio - val_ratio\n","batch_size = 32"],"metadata":{"id":"2gLseCaixj2Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#shutil.rmtree(refined_data)"],"metadata":{"id":"gMXd5j19IvTT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_list = []\n","\n","for class_n in os.listdir(data_dir):\n","    file_list += [os.path.join(data_dir,class_n,x) for x in os.listdir(os.path.join(data_dir,class_n))]"],"metadata":{"id":"tIP5EQEryQA6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(file_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KYcViWq8yZ3W","executionInfo":{"status":"ok","timestamp":1669860597108,"user_tz":-330,"elapsed":11,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"}},"outputId":"fd329234-c348-4b91-95c1-f116b49f6cc4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8965"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["def break_into_time_frames(coords,vid_size,time_window=50,stride=40):\n","    shape = coords.shape\n","    [h,w] = vid_size\n","    \n","    #[x,y,z] is the format\n","    if shape[0]<time_window:\n","        return None\n","    \n","    frame_points = list(range(0,shape[0]-time_window,stride))\n","    arrays = []\n","    for i in frame_points:\n","        arrays.append(coords[i:i+time_window])\n","    return arrays\n","\n","def save_arrays(data_dir,file_name,class_name,arrays,vid_size):\n","    for __id,each_array in enumerate(arrays):\n","        np.savez(os.path.join(data_dir,f\"{class_name}_cls_{file_name}_{__id}.npz\"),coords=each_array,video_size=vid_size)\n","\n","\n","def classname_id(class_name_list):\n","    id2classname = {k:v for k, v in zip(list(range(len(class_name_list))),class_name_list)}\n","    classname2id = {v:k for k, v in id2classname.items()}\n","    return id2classname, classname2id"],"metadata":{"id":"WiNVqGnpyb4r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gen_required = False"],"metadata":{"id":"HDsxBhw7cKcQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if gen_required:\n","  os.makedirs(refined_data,exist_ok=True)\n","  for each_file in tqdm(file_list):\n","      a_file = np.load(each_file)\n","      coords, vid_size = a_file[\"coords\"],a_file[\"video_size\"]\n","      f_point = break_into_time_frames(coords,vid_size)\n","      \n","      path_parts = each_file.strip().split(\"/\")\n","      class_n = path_parts[-2]\n","      file_id = path_parts[-1].split(\".\")[0]\n","      \n","      #print(class_n, file_id)\n","      if f_point:\n","          save_arrays(refined_data,file_id,class_n,f_point,vid_size)"],"metadata":{"id":"gaCMfVHKyfOW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(os.listdir(refined_data)),np.load(f\"{refined_data}/brush_hair_cls_April_09_brush_hair_u_nm_np1_ba_goo_1_0.npz\")[\"coords\"].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rfQ3SNCUyjIK","executionInfo":{"status":"ok","timestamp":1669860702120,"user_tz":-330,"elapsed":95300,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"}},"outputId":"e5205278-00b8-4ba5-dfb3-2db706baa1b5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(17653, (50, 33, 3))"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["data_dir = refined_data"],"metadata":{"id":"-AGyBfJKyrLK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["id2clsname, clsname2id = classname_id(class_names)"],"metadata":{"id":"A9MHVsK7zFY3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_file_list = []\n","val_file_list = []\n","test_file_list = []\n","\n","file_list = [os.path.join(data_dir,x) for x in os.listdir(data_dir)]\n","\n","random.shuffle(file_list)\n","num_list = len(file_list)\n","\n","train_range = [0,int(num_list*train_ratio)]\n","val_range = [int(num_list*train_ratio),int(num_list*(train_ratio+val_ratio))]\n","test_range = [int(num_list*(train_ratio+val_ratio)),num_list-1]\n","\n","train_file_list += file_list[train_range[0]:train_range[1]]\n","val_file_list += file_list[val_range[0]:val_range[1]]\n","test_file_list += file_list[test_range[0]:test_range[1]]"],"metadata":{"id":"3FWyqtCmzSkT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(train_file_list),len(val_file_list),len(test_file_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ArrBtSnhzVjm","executionInfo":{"status":"ok","timestamp":1669860702672,"user_tz":-330,"elapsed":6,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"}},"outputId":"426ebb06-7984-4c2e-f882-a9b9b91cf5e4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(12357, 2648, 2647)"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["train_file_list = train_file_list[:(len(train_file_list)//batch_size)*batch_size]\n","val_file_list = val_file_list[:(len(val_file_list)//batch_size)*batch_size]\n","test_file_list = test_file_list[:(len(test_file_list)//batch_size)*batch_size]"],"metadata":{"id":"72A5WTGbzX40"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(train_file_list),len(val_file_list),len(test_file_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ym9kfxwzaD8","executionInfo":{"status":"ok","timestamp":1669860702672,"user_tz":-330,"elapsed":5,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"}},"outputId":"d2000ce6-4284-435f-d26f-4d3b7e5aa40a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(12352, 2624, 2624)"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["class SkeletonDataset(Dataset):\n","    def __init__(self, file_list,class2id, transform=None, target_transform=None):\n","        self.file_list = file_list\n","        self.transform = transform\n","        self.class2id = class2id\n","        self.target_transform = target_transform\n","\n","    def __len__(self):\n","        return len(self.file_list)\n","\n","    def __getitem__(self, idx):\n","        a_file = np.load(self.file_list[idx])\n","        action_type = self.file_list[idx].strip().split(\"/\")[-1].split(\"_cls_\")[0]\n","        coords, vid_size = a_file[\"coords\"],a_file[\"video_size\"]\n","        \n","        shape = coords.shape\n","        \n","        coords = torch.from_numpy(coords).float()\n","        \n","        coords = torch.reshape(coords, (shape[0], shape[1]*shape[2]))\n","        label = torch.clone(coords)\n","        \n","        if self.transform:\n","            coords = self.transform(coords)\n","        if self.target_transform:\n","            label = self.target_transform(coords)\n","        return coords, label, self.class2id[action_type]"],"metadata":{"id":"dwwdJqoNzcP_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data = SkeletonDataset(train_file_list,clsname2id)\n","val_data = SkeletonDataset(val_file_list,clsname2id)\n","test_data = SkeletonDataset(test_file_list,clsname2id)"],"metadata":{"id":"S9W_8_Aqze-8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dl = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n","val_dl = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n","test_dl = DataLoader(test_data, batch_size=batch_size, shuffle=False)"],"metadata":{"id":"REQXHK73zhWy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BiLSTMEncoder(nn.Module):\n","    def __init__(self, input_size, hidden_size,device=None, num_layers = 1):\n","        super(BiLSTMEncoder, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        if device:\n","          self.device = device\n","        else:\n","          self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","        # define LSTM layer\n","        self.linear1 = nn.Linear(self.input_size, 128)\n","        self.linear2 = nn.Linear(128, 256)\n","        self.linear3 = nn.Linear(256, 512)\n","        self.lstm = nn.LSTM(input_size = 512, hidden_size = self.hidden_size,\n","                            num_layers = self.num_layers, bidirectional=True,\n","                            batch_first=True)\n","        \n","        \n","\n","    def forward(self, x_input):\n","        '''\n","        : param x_input:               input of shape (seq_len, # in batch, input_size)\n","        : return lstm_out, hidden:     lstm_out gives all the hidden states in the sequence; hidden gives the hidden state and cell state for the last element in the sequence                         \n","        '''\n","        x = self.linear1(x_input)\n","        x = self.linear2(x)\n","        x = self.linear3(x)\n","        \n","        lstm_out, self.hidden = self.lstm(x)\n","        hidden_transformed = torch.concat(self.hidden,0)\n","        hidden_transformed = torch.transpose(hidden_transformed,0,1)\n","        hidden_transformed = torch.flatten(hidden_transformed,start_dim=1)\n","        \n","        return lstm_out, hidden_transformed.to(device)\n","    \n","class BiLSTMDecoder(nn.Module):\n","    def __init__(self, input_size, hidden_size,device=None, num_layers = 1):\n","        super(BiLSTMDecoder, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        if device:\n","          self.device = device\n","        else:\n","          self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","        # define LSTM layer\n","        self.linear1 = nn.Linear(128, self.input_size)\n","        self.linear2 = nn.Linear(256, 128)\n","        self.linear3 = nn.Linear(512, 256)\n","        self.linear4 = nn.Linear(1024, 512)\n","        \n","        self.lstm = nn.LSTM(input_size = 512, hidden_size = self.hidden_size,\n","                            num_layers = self.num_layers, bidirectional=True,\n","                            batch_first=True)\n","        \n","        \n","\n","    def forward(self,encoder_hidden):\n","        '''\n","        : param x_input:               input of shape (seq_len, # in batch, input_size)\n","        : return lstm_out, hidden:     lstm_out gives all the hidden states in the sequence; hidden gives the hidden state and cell state for the last element in the sequence                         \n","        '''\n","        \n","        hidden_shape = encoder_hidden.shape\n","        \n","        hidden = encoder_hidden.view((hidden_shape[0],4,512))\n","        hidden = torch.transpose(hidden,1,0)\n","        h1,h2,c1,c2 = torch.unbind(hidden,0)\n","        h,c = torch.stack((h1,h2)),torch.stack((c1,c2))\n","        \n","        dummy_input = torch.rand((32,50,512), requires_grad=True)\n","        \n","        lstm_out, self.hidden = self.lstm(dummy_input,(h,c))\n","        x = self.linear4(lstm_out)\n","        x = self.linear3(x)\n","        x = self.linear2(x)\n","        x = self.linear1(x)\n","        \n","        return x\n","\n","class BiLSTMEncDecModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers = 1):\n","        super(BiLSTMEncDecModel, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        \n","        self.encoder = BiLSTMEncoder(input_size,hidden_size,self.device)\n","        self.decoder = BiLSTMDecoder(input_size,hidden_size,self.device)\n","        \n","    def forward(self,x):\n","        lstm_out,embedding = self.encoder(x)\n","        embedding = embedding.to(self.device)\n","        decoder_out = self.decoder(embedding)\n","        \n","        return decoder_out\n","        \n","\n","        \n","        \n","        \n","        \n","        \n","        "],"metadata":{"id":"JDFQpOGHzjMr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoder = BiLSTMEncoder(99,512)\n","decoder = BiLSTMDecoder(99,512)\n","\n","bilstm_model = BiLSTMEncDecModel(99,512)"],"metadata":{"id":"xAg3zXChznPg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lstm_out, embedding = encoder(torch.randn((32,50,99)))"],"metadata":{"id":"2XWqsEhpzqEq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["decoder_out = decoder(embedding)"],"metadata":{"id":"an_K4SoGzsrA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_out = bilstm_model(torch.randn((32,50,99)))\n","model_out.shape"],"metadata":{"id":"qCK5c4l2zuzm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"MN40e6xfz1zF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_model(model, train_dataset, val_dataset, n_epochs):\n","    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","    std_loss = nn.L1Loss(reduction='sum').to(device)\n","    #contrastive_loss = SupConLoss(contrast_mode=\"one\").to(device)\n","    history = dict(train=[], val=[])\n","    model.to(device)\n","    \n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_loss = 10000.0\n","  \n","    for epoch in range(1, n_epochs + 1):\n","        model = model.train()\n","\n","        train_losses = []\n","        for in_seq,tar_seq,action in tqdm(train_dataset):\n","            optimizer.zero_grad()\n","            \n","            in_seq = in_seq.to(device)\n","            tar_seq = tar_seq.to(device)\n","            seq_pred = model(in_seq)\n","            \n","            loss = std_loss(seq_pred, tar_seq)\n","            #loss += 0.5*contrastive_loss(embed,labels=sample_label.view(-1))\n","            #print(contrastive_loss(embed,labels=sample_label.view(-1)))\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_losses.append(loss.item())\n","\n","        val_losses = []\n","        model = model.eval()\n","        with torch.no_grad():\n","            for in_seq,tar_seq,action in val_dataset:\n","\n","                in_seq = in_seq.to(device)\n","                tar_seq = tar_seq.to(device)\n","                seq_pred = model(in_seq)\n","\n","                loss = std_loss(seq_pred, tar_seq)\n","                #loss += 0.5*contrastive_loss(embed,labels=sample_label.view(-1))\n","                val_losses.append(loss.item())\n","\n","        train_loss = np.mean(train_losses)\n","        val_loss = np.mean(val_losses)\n","\n","        history['train'].append(train_loss)\n","        history['val'].append(val_loss)\n","\n","        if val_loss < best_loss:\n","            best_loss = val_loss\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","\n","        print(f'Epoch {epoch}: train loss {train_loss} val loss {val_loss}')\n","\n","    model.load_state_dict(best_model_wts)\n","    return model.eval(), history"],"metadata":{"id":"wz8JfCZ2z4Bv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model, history = train_model(\n","  bilstm_model, \n","  train_dl, \n","  val_dl, \n","  n_epochs=500\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":389},"id":"Cw5XSsFCz6DV","executionInfo":{"status":"error","timestamp":1669860785365,"user_tz":-330,"elapsed":3666,"user":{"displayName":"Devin De Silva","userId":"07966168235963805458"}},"outputId":"bd89177d-ec77-49a4-b336-8402dc7cc340"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/386 [00:00<?, ?it/s]\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-60313d6844c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mval_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n","\u001b[0;32m<ipython-input-27-4ba181df980c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataset, val_dataset, n_epochs)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0min_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mtar_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtar_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mseq_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-25f827a18602>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mdecoder_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecoder_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-25f827a18602>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, encoder_hidden)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mdummy_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 770\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    771\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n","\u001b[0;31mRuntimeError\u001b[0m: Input and hidden tensors are not at the same device, found input tensor at cpu and hidden tensor at cuda:0"]}]},{"cell_type":"code","source":["ax = plt.figure().gca()\n","\n","ax.plot(history['train'])\n","ax.plot(history['val'])\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['train', 'test'])\n","plt.title('Loss over training epochs')\n","plt.show();"],"metadata":{"id":"ruxZSj5Az_eQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gQRrSLfd0B_w"},"execution_count":null,"outputs":[]}]}