{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1KPEw9iWWVmGhlhrQKGlR_Bs7byx1TCH_","timestamp":1677984555602},{"file_id":"1CTJmtd3zarhF9M3fOk5g9zS6mZKy2XP8","timestamp":1677944836036}],"mount_file_id":"1CTJmtd3zarhF9M3fOk5g9zS6mZKy2XP8","authorship_tag":"ABX9TyP12TpujtSy7HeIxDMVIvjr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"NJhThY8PC2si","colab":{"base_uri":"https://localhost:8080/","height":328},"executionInfo":{"status":"error","timestamp":1678021547556,"user_tz":-330,"elapsed":221653,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}},"outputId":"3ead3a86-d977-4309-d093-db902fd2b419"},"outputs":[{"output_type":"error","ename":"MessageError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    121\u001b[0m       'TBE_EPHEM_CREDS_ADDR'] if ephemeral else _os.environ['TBE_CREDS_ADDR']\n\u001b[1;32m    122\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    124\u001b[0m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   request_id = send_request(\n\u001b[1;32m    170\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    100\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    101\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["data_root = '/content/drive/MyDrive/22_FYP42 - Zero-shot Explainable HAR/Datasets/Consolidated/PAMPA2'"],"metadata":{"id":"5XJFNoLnD4Zw","executionInfo":{"status":"aborted","timestamp":1678021547557,"user_tz":-330,"elapsed":19,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! git clone https://github.com/nipdep/HAR-ZSL-XAI.git --branch pd/PoseAE --single-branch\n","! mv /content/HAR-ZSL-XAI/src /content/"],"metadata":{"id":"khVPupusDG8T","executionInfo":{"status":"aborted","timestamp":1678021547557,"user_tz":-330,"elapsed":19,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"5G3REk2jDHN1"}},{"cell_type":"code","source":["import os \n","from datetime import date, datetime\n","from tqdm.autonotebook import tqdm\n","from copy import deepcopy\n","from collections import defaultdict\n","import numpy as np \n","import numpy.random as random\n","import pandas as pd\n","import json\n","from collections import defaultdict, OrderedDict\n","\n","import torch \n","from torch import nn, Tensor\n","from torch.nn import functional as F\n","from torch.nn.modules import MultiheadAttention, Linear, Dropout, BatchNorm1d, TransformerEncoderLayer\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim import Adam\n","from torch.nn import MSELoss\n","\n","\n","from src.datasets.data import PAMAP2Reader, PAMAP2ReaderV2\n","# from src.datasets.dataset import PAMAP2Dataset\n","from src.utils.analysis import action_evaluator\n","from src.datasets.utils import load_attribute\n","\n","from src.models.loss import FeatureLoss, AttributeLoss\n","from src.utils.losses import *\n","from src.utils.analysis import action_evaluator\n","\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.decomposition import PCA \n","\n","# from src.running import train_step1, eval_step1"],"metadata":{"id":"DWgMHHXXDG5n","executionInfo":{"status":"aborted","timestamp":1678021547557,"user_tz":-330,"elapsed":18,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.manifold import TSNE\n","# from umap import UMAP\n","\n","import matplotlib.pyplot as plt \n","import seaborn as sns \n","import plotly.express as px"],"metadata":{"id":"enxG_kfLUdK9","executionInfo":{"status":"aborted","timestamp":1678021547558,"user_tz":-330,"elapsed":19,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# setup model configurations\n","config = {\n","    # general information\n","    \"experiment-name\": \"test-001\", \n","    \"datetime\": date.today(),\n","    \"device\": \"gpu\",\n","    \"dataset\": \"PAMAP2\", # \"PAMAP2\", \"DaLiAc\", \"UTD\"\n","    \"Model\": \"RelativeGlobalAttention\",\n","    \n","    \"sem-space\": 'attr',\n","    # model training configs\n","    \"model_params\":{\n","        \"linear_filters\":[512,1024,1024,256],\n","        \"input_feat\":36,\n","        \"dropout\":0.1,\n","    },\n","    \"include_attribute_loss\": True, \n","    \"n_actions\": 18,\n","    \"folding\": True,\n","    \"lr\": 0.001,\n","    \"ae_lr\": 0.0001,\n","    \"imu_lr\": 0.0004,\n","    \"ae_alpha\": 0.9,\n","    \"imu_alpha\": 0.0001,\n","    \"n_epochs\": 15,\n","    \"optimizer\": \"adam\",\n","    \"batch_size\": 32,\n","    \"semantic_loss\": \"cosine_distance\",\n","    # model configs\n","    \"d_model\": 128, \n","    \"num_heads\": 2,\n","    \"feat_size\": 128, # skel-AE hidden size and IMU-Anc output size\n","    \"semantic_size\": 64,\n","    # dataset configs\n","    \"window_size\": 5, \n","    \"overlap\": 0.5,\n","    \"seq_len\": 50,  # skeleton seq. length\n","    \"seen_split\": 0.2,\n","    \"unseen_split\": 0.8\n","}"],"metadata":{"id":"umHwAr5pDG2N","executionInfo":{"status":"aborted","timestamp":1678021547558,"user_tz":-330,"elapsed":19,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_model(model,model_name,unique_name,fold_id):\n","    PATH = f\"{models_saves}/{model_name}\"\n","    os.makedirs(PATH,exist_ok=True)\n","    torch.save({\n","        \"n_epochs\" : config[\"n_epochs\"],\n","        \"model_state_dict\":model.state_dict(),\n","        \"config\": config\n","    }, f\"{PATH}/{unique_name}_{fold_id}.pt\")\n","\n","model_iden = \"fold\"\n","notebook_iden = \"SORTModel_feature\"\n","models_saves = \"model_saves\""],"metadata":{"id":"HpuaMQupDNPI","executionInfo":{"status":"aborted","timestamp":1678021547558,"user_tz":-330,"elapsed":19,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["IMU_data_path = data_root+'/IMU/Protocol/'\n","dataReader = PAMAP2Reader(IMU_data_path)\n","actionList = dataReader.idToLabel"],"metadata":{"id":"qQcUv5ikFZyN","executionInfo":{"status":"aborted","timestamp":1678021547559,"user_tz":-330,"elapsed":20,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SOTAEmbedding(nn.Module):\n","    def __init__(self, linear_filters=[1024,1024,1024,2048],input_feat=36, dropout=0.1):\n","        super(SOTAEmbedding, self).__init__()\n","        self.input_feat = input_feat\n","        self.linear_filters = linear_filters\n","        self.input_feat = input_feat\n","        self.dropout = dropout\n","\n","        self.linear1 = nn.Linear(input_feat,linear_filters[0])\n","        self.batch_norm1 = nn.BatchNorm1d(linear_filters[0])\n","        self.linear2 = nn.Linear(linear_filters[0],linear_filters[1])\n","        self.batch_norm2 = nn.BatchNorm1d(linear_filters[1])\n","        self.linear3 = nn.Linear(linear_filters[1],linear_filters[2])\n","        self.batch_norm3 = nn.BatchNorm1d(linear_filters[2])\n","        self.linear4 = nn.Linear(linear_filters[2]+linear_filters[1]+linear_filters[0],linear_filters[3])\n","        self.batch_norm4 = nn.BatchNorm1d(linear_filters[3])\n","        self.act = F.relu\n","\n","\n","\n","    def forward(self, x):\n","        #layer1\n","        out1 = self.linear1(x)\n","        out1 = self.batch_norm1(out1)\n","        out1 = self.act(out1)\n","\n","        #layer2\n","        out2 = self.linear2(out1)\n","        out2 = self.batch_norm2(out2)\n","        out2 = self.act(out2)\n","\n","        #layer3\n","        out3 = self.linear3(out2)\n","        out3 = self.batch_norm3(out3)\n","        out3 = self.act(out3)\n","\n","        concat = torch.cat([out1,out2,out3],-1)\n","\n","        #layer4\n","        out4 = self.linear4(concat)\n","        out4 = self.batch_norm4(out4)\n","        out4 = self.act(out4)\n","        return out4"],"metadata":{"id":"4WULQEobFzPO","executionInfo":{"status":"aborted","timestamp":1678021547559,"user_tz":-330,"elapsed":19,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = SOTAEmbedding(\n","    linear_filters=config[\"model_params\"][\"linear_filters\"],\n","    input_feat=config[\"model_params\"][\"input_feat\"],\n","    dropout=config[\"model_params\"][\"dropout\"]\n",")"],"metadata":{"id":"_55KyylYF1cF","executionInfo":{"status":"aborted","timestamp":1678021547560,"user_tz":-330,"elapsed":20,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["emb = model(torch.randn((32,36)))\n","emb.size()"],"metadata":{"id":"R11Op4zIF4jl","executionInfo":{"status":"aborted","timestamp":1678021547560,"user_tz":-330,"elapsed":19,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["emb"],"metadata":{"id":"-KfXOOZfF5v9","executionInfo":{"status":"aborted","timestamp":1678021547560,"user_tz":-330,"elapsed":19,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load video dataset\n","I3D_data_path  = data_root + '/I3D/feat_dict_2048.npz'\n","video_data = np.load(I3D_data_path)\n","video_classes, video_feat = video_data['activity'], video_data['features']"],"metadata":{"id":"YAO5neZHGJKL","executionInfo":{"status":"aborted","timestamp":1678021547560,"user_tz":-330,"elapsed":19,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pca_256 = PCA(n_components=128, random_state=101)\n","pca_256.fit(video_feat)\n","video_feat = pca_256.transform(video_feat)"],"metadata":{"id":"e9w3_50ALzEY","executionInfo":{"status":"aborted","timestamp":1678021547561,"user_tz":-330,"elapsed":20,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["video_feat.shape"],"metadata":{"id":"lwfEZ6wIHGDb","executionInfo":{"status":"aborted","timestamp":1678021547561,"user_tz":-330,"elapsed":19,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vid_cls_name = np.unique(video_classes)"],"metadata":{"id":"SOXax1ZpHVjg","executionInfo":{"status":"aborted","timestamp":1678021547561,"user_tz":-330,"elapsed":19,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PAMAP2Dataset(Dataset):\n","    def __init__(self, data, actions, attributes, attribute_dict, action_classes, seq_len=120):\n","        super(PAMAP2Dataset, self).__init__()\n","        self.data = torch.from_numpy(data)\n","        self.actions = actions\n","        self.attribute_dict = attribute_dict\n","        self.seq_len = seq_len\n","        self.attributes = torch.from_numpy(attributes)\n","        self.action_classes = action_classes\n","        # build action to id mapping dict\n","        self.n_action = len(self.actions)\n","        self.action2Id = dict(zip(action_classes, range(self.n_action)))\n","\n","    def __getitem__(self, ind):\n","        x = self.data[ind, ...]\n","        target = self.actions[ind]\n","        y = torch.from_numpy(np.array([self.action2Id[target]]))\n","        # extraction semantic space generation skeleton sequences\n","        vid_idx = random.choice(self.attribute_dict[target])\n","        y_feat = self.attributes[vid_idx, ...]\n","        return x, y, y_feat\n","\n","    def __len__(self):\n","        return self.data.shape[0]\n","\n","    def getClassAttrs(self):\n","        sampling_idx = [random.choice(self.attribute_dict[i]) for i in self.action_classes]\n","        ft_mat = self.attributes[sampling_idx, ...]\n","        return ft_mat\n","\n","    def getClassFeatures(self):\n","        cls_feat = []\n","        for c in self.action_classes:\n","            idx = self.attribute_dict[c]\n","            cls_feat.append(torch.mean(self.attributes[idx, ...], dim=0))\n","\n","        cls_feat = torch.vstack(cls_feat)\n","        # print(cls_feat.size())\n","        return cls_feat"],"metadata":{"id":"oMgevInhKbjy","executionInfo":{"status":"aborted","timestamp":1678021547562,"user_tz":-330,"elapsed":18,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class IMUEncoder(nn.Module):\n","    def __init__(self, in_ft, d_model, ft_size, n_classes, num_heads=1, max_len=1024, dropout=0.1):\n","        super(IMUEncoder, self).__init__()\n","        self.in_ft = in_ft\n","        self.max_len = max_len\n","        self.d_model = d_model\n","        self.num_heads = num_heads\n","        self.ft_size = ft_size \n","        self.n_classes = n_classes\n","\n","        self.lstm = nn.LSTM(input_size=self.in_ft,\n","                            hidden_size=self.d_model,\n","                            num_layers=self.num_heads,\n","                            batch_first=True,\n","                            bidirectional=True)\n","        self.drop = nn.Dropout(p=0.1)\n","        self.act = nn.ReLU()\n","        self.fcLayer1 = nn.Linear(2*self.d_model, self.ft_size)\n","        # self.fcLayer2 = nn.Linear(self.ft_size, self.ft_size)\n","\n","    def forward(self, x):\n","        out, _ = self.lstm(x)\n","        out_forward = out[:, self.max_len - 1, :self.d_model]\n","        out_reverse = out[:, 0, self.d_model:]\n","        out_reduced = torch.cat((out_forward, out_reverse), 1)\n","        out = self.drop(out_reduced)\n","        out = self.act(out)\n","        out = self.fcLayer1(out)\n","        # out = self.fcLayer2(out)\n","        return out"],"metadata":{"id":"FIWrGZwzUnbQ","executionInfo":{"status":"aborted","timestamp":1678021547562,"user_tz":-330,"elapsed":17,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test model \n","sample_input = torch.randn((32, 120, 42))\n","model = IMUEncoder(in_ft=42, d_model=128, num_heads=2, ft_size=128, n_classes=2, max_len=120, dropout=0.1)\n","sample_output = model(sample_input)\n","sample_output.shape"],"metadata":{"id":"c9mbOqLLUpB0","executionInfo":{"status":"aborted","timestamp":1678021547562,"user_tz":-330,"elapsed":16,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"RKpMzwHKGAQ2"}},{"cell_type":"code","source":["if config['device'] == 'cpu':\n","    device = \"cpu\"\n","else:\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"NsH-K0HpF7tu","executionInfo":{"status":"aborted","timestamp":1678021547563,"user_tz":-330,"elapsed":17,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# run 5-fold running\n","fold_classes = [['watching TV', 'house cleaning', 'standing', 'ascending stairs'], ['walking', 'rope jumping', 'sitting', 'descending stairs'], ['playing soccer', 'lying', 'vacuum cleaning', 'computer work'], ['cycling', 'running', 'Nordic walking'], ['ironing', 'car driving', 'folding laundry']]\n","\n","fold_cls_ids = [[actionList.index(i) for i in j] for j in fold_classes]"],"metadata":{"id":"c9Lp6g_IGCJs","executionInfo":{"status":"aborted","timestamp":1678021547563,"user_tz":-330,"elapsed":17,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def selecting_video_prototypes(prototypes:np.array,classes:np.array,vid_class_name:np.array):\n","    selected = []\n","    for tar in vid_class_name:\n","        indexes = np.where(classes == tar)\n","        selected.append(torch.from_numpy(prototypes[random.choice(indexes[0])]))\n","\n","    return torch.stack(selected)"],"metadata":{"id":"8CjwLpCGGDh0","executionInfo":{"status":"aborted","timestamp":1678021547564,"user_tz":-330,"elapsed":17,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["selecting_video_prototypes(video_feat,video_classes,vid_cls_name).shape"],"metadata":{"id":"P4hX2XoCHYhc","executionInfo":{"status":"aborted","timestamp":1678021547564,"user_tz":-330,"elapsed":17,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataReader.label_map"],"metadata":{"id":"Mr2jZegpHaJ7","executionInfo":{"status":"aborted","timestamp":1678021547565,"user_tz":-330,"elapsed":18,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label2Id = {c[1]:i for i,c in enumerate(dataReader.label_map)}\n","action_dict = defaultdict(list)\n","skeleton_Ids = []\n","for i, a in enumerate(video_classes):\n","    action_dict[label2Id[a]].append(i)\n","    skeleton_Ids.append(label2Id[a])"],"metadata":{"id":"lAn_s4UyHctk","executionInfo":{"status":"aborted","timestamp":1678021547565,"user_tz":-330,"elapsed":18,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_dict = dataReader.generate(unseen_classes=fold_cls_ids[0], seen_ratio=0.2, unseen_ratio=0.8, window_size=5.21, window_overlap=4.21, resample_freq=20)"],"metadata":{"id":"W-guaLIXHmKs","executionInfo":{"status":"aborted","timestamp":1678021547565,"user_tz":-330,"elapsed":18,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_dict['train']['X'].shape,data_dict['eval-seen']['X'].shape,data_dict[\"test\"][\"X\"].shape"],"metadata":{"id":"rICanDMvHqKb","executionInfo":{"status":"aborted","timestamp":1678021547565,"user_tz":-330,"elapsed":18,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def loss_cross_entropy(\n","        y_pred:torch.Tensor,\n","        cls:torch.Tensor,\n","        selected_features,\n","        loss_fn=nn.CrossEntropyLoss(reduction=\"sum\")\n","):\n","    num_classes = selected_features.size()[0]\n","    #print(selected_features)\n","    cosine_sim_comb = []\n","    for entry in y_pred.unbind():\n","        #print(entry.repeat(num_classes,1),selected_features.size())\n","        cosine_sim = F.softmax(F.cosine_similarity(entry.repeat(num_classes,1),selected_features),dim=-1)\n","        cosine_sim_comb.append(cosine_sim)\n","\n","    cosine_sim_comb = torch.stack(cosine_sim_comb)\n","    loss = loss_fn(cosine_sim_comb,cls)\n","    #print(loss)\n","    return loss\n","\n","def loss_reconstruction_calc(y_pred:torch.Tensor,y_feat:torch.Tensor,loss_fn=nn.L1Loss(reduction=\"sum\")):\n","    bat_size,feature_size = y_pred.size()\n","    loss = loss_fn(y_pred,y_feat)*(1/feature_size)\n","    #print(loss)\n","    return loss\n","\n","def predict_class(\n","        y_pred:torch.Tensor,\n","        selected_features):\n","\n","    num_classes = selected_features.size()[0]\n","\n","    cosine_sim_comb = []\n","    for entry in y_pred.unbind():\n","        cosine_sim = torch.argmax(F.softmax(F.cosine_similarity(entry.repeat(num_classes,1),selected_features),dim=-1))\n","        cosine_sim_comb.append(cosine_sim)\n","\n","    pred = torch.stack(cosine_sim_comb)\n","    return pred"],"metadata":{"id":"FBzAK08GHu6z","executionInfo":{"status":"aborted","timestamp":1678021547566,"user_tz":-330,"elapsed":19,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_step(model, dataloader, dataset:PAMAP2Dataset, optimizer, loss_module, device, class_names, phase='train', l2_reg=False, loss_alpha=0.7):\n","    model = model.train()\n","    epoch_loss = 0  # total loss of epoch\n","    total_samples = 0  # total samples in epoch\n","    random_selected_feat = dataset.getClassFeatures().to(device)\n","\n","    with tqdm(dataloader, unit=\"batch\", desc=phase) as tepoch:\n","        for batch in tepoch:\n","            X, targets, target_feat = batch\n","            X = X.float().to(device)\n","            target_feat = target_feat.float().to(device)\n","            targets = targets.long().to(device)\n","\n","            # Zero gradients, perform a backward pass, and update the weights.\n","            optimizer.zero_grad()\n","            # forward\n","            # track history if only in train\n","            with torch.set_grad_enabled(phase == 'train'):\n","            # with autocast():\n","                feat_output = model(X)\n","                class_loss = loss_cross_entropy(feat_output,targets.squeeze(),random_selected_feat,loss_fn =loss_module['class'] )\n","                feat_loss = loss_reconstruction_calc(feat_output,target_feat,loss_fn=loss_module[\"feature\"])\n","\n","            #loss = cross_entropy_loss\n","            loss = feat_loss + loss_alpha*class_loss\n","            class_output = predict_class(feat_output,random_selected_feat)\n","\n","            if phase == 'train':\n","                loss.backward()\n","                optimizer.step()\n","\n","            metrics = {\"loss\": loss.item()}\n","            with torch.no_grad():\n","                total_samples += len(targets)\n","                epoch_loss += loss.item()  # add total loss of batch\n","\n","            # convert feature vector into action class\n","            # using cosine\n","            pred_class = class_output.cpu().detach().numpy()\n","            metrics[\"accuracy\"] = accuracy_score(y_true=targets.cpu().detach().numpy(), y_pred=pred_class)\n","            tepoch.set_postfix(metrics)\n","\n","    epoch_loss = epoch_loss / total_samples  # average loss per sample for whole epoch\n","    return metrics"],"metadata":{"id":"NOS3PISDH6ir","executionInfo":{"status":"aborted","timestamp":1678021547566,"user_tz":-330,"elapsed":18,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def eval_step(model, dataloader,dataset, loss_module, device, class_names,  phase='seen', l2_reg=False, print_report=True, loss_alpha=0.7):\n","    model = model.eval()\n","    random_selected_feat = dataset.getClassFeatures().to(device)\n","    epoch_loss = 0  # total loss of epoch\n","    total_samples = 0  # total samples in epoch\n","    per_batch = {'target_masks': [], 'targets': [], 'predictions': [], 'metrics': [], 'IDs': []}\n","    metrics = {\"samples\": 0, \"loss\": 0, \"feat. loss\": 0, \"classi. loss\": 0}\n","\n","    with tqdm(dataloader, unit=\"batch\", desc=phase) as tepoch:\n","        for batch in tepoch:\n","            X, targets, target_feat = batch\n","            X = X.float().to(device)\n","            X = X.float().to(device)\n","            target_feat = target_feat.float().to(device)\n","            targets = targets.long().to(device)\n","\n","            # forward\n","            # track history if only in train\n","            with torch.set_grad_enabled(phase == 'train'):\n","            # with autocast():\n","                feat_output = model(X)\n","                class_loss = loss_cross_entropy(feat_output,targets.squeeze(),random_selected_feat,loss_fn =loss_module['class'] )\n","                feat_loss = loss_reconstruction_calc(feat_output,target_feat,loss_fn=loss_module[\"feature\"])\n","            \n","            #loss = cross_entropy_loss\n","            loss = feat_loss + loss_alpha*class_loss\n","            class_output = predict_class(feat_output,random_selected_feat)\n","\n","            # convert feature vector into action class\n","            # using cosine\n","            if phase == 'seen':\n","                pred_action = class_output\n","            else:\n","                #feat_numpy = torch.sigmoid(feat_output.cpu().detach())\n","                #action_probs = cosine_similarity(feat_numpy, target_feat_met)\n","                pred_action = class_output\n","\n","            with torch.no_grad():\n","                metrics['samples'] += len(targets)\n","                metrics['loss'] += loss.item()  # add total loss of batch\n","                metrics['feat. loss'] += feat_loss.item()\n","                metrics['classi. loss'] += class_loss.item()\n","\n","            per_batch['targets'].append(targets.cpu().numpy())\n","            per_batch['predictions'].append(pred_action.cpu().numpy())\n","            per_batch['metrics'].append([loss.cpu().numpy()])\n","\n","            tepoch.set_postfix({\"loss\": loss.item()})\n","\n","    all_preds = np.concatenate(per_batch[\"predictions\"])\n","    all_targets = np.concatenate(per_batch[\"targets\"])\n","    metrics_dict = action_evaluator(y_pred=all_preds, y_true=all_targets[:, 0], class_names=class_names, print_report=print_report)\n","    metrics_dict.update(metrics)\n","    return metrics_dict"],"metadata":{"id":"jYNZfoaMH_Xr","executionInfo":{"status":"aborted","timestamp":1678021547566,"user_tz":-330,"elapsed":18,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_curves(df):\n","    df['loss'] = df['loss']/df['samples']\n","    df['feat. loss'] = df['feat. loss']/df['samples']\n","    df['classi. loss'] = df['classi. loss']/df['samples']\n","    \n","    fig, axs = plt.subplots(nrows=4)\n","    sns.lineplot(data=df, x='epoch', y='loss', hue='phase', marker='o', ax=axs[2]).set(title=\"Loss\")\n","    sns.lineplot(data=df, x='epoch', y='feat. loss', hue='phase', marker='o', ax=axs[0]).set(title=\"Feature Loss\")\n","    sns.lineplot(data=df, x='epoch', y='classi. loss', hue='phase', marker='o', ax=axs[1]).set(title=\"Classification Loss\")\n","    sns.lineplot(data=df, x='epoch', y='accuracy', hue='phase', marker='o', ax=axs[3]).set(title=\"Accuracy\")"],"metadata":{"id":"5Y6DXbpRjfIM","executionInfo":{"status":"aborted","timestamp":1678021547566,"user_tz":-330,"elapsed":18,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fold_metric_scores = []\n","for i, cs in enumerate(fold_cls_ids):\n","    print(\"=\"*16, f'Fold-{i}', \"=\"*16)\n","    print(f'Unseen Classes : {fold_classes[i]}')\n","\n","    data_dict = dataReader.generate(unseen_classes=cs, seen_ratio=config['seen_split'], unseen_ratio=config['unseen_split'], window_size=5.21, window_overlap=4.21, resample_freq=20)\n","    all_classes = dataReader.idToLabel\n","    seen_classes = data_dict['seen_classes']\n","    unseen_classes = data_dict['unseen_classes']\n","    print(\"seen classes > \", seen_classes)\n","    print(\"unseen classes > \", unseen_classes)\n","    train_n, seq_len, in_ft = data_dict['train']['X'].shape\n","\n","    print(\"Initiate IMU datasets ...\")\n","    # build IMU datasets\n","    train_dt = PAMAP2Dataset(data=data_dict['train']['X'], actions=data_dict['train']['y'], attributes=video_feat, attribute_dict=action_dict, action_classes=seen_classes, seq_len=100)\n","    train_dl = DataLoader(train_dt, batch_size=config['batch_size'], shuffle=True, pin_memory=True, drop_last=True)\n","    # build seen eval_dt\n","    eval_dt = PAMAP2Dataset(data=data_dict['eval-seen']['X'], actions=data_dict['eval-seen']['y'], attributes=video_feat, attribute_dict=action_dict, action_classes=seen_classes, seq_len=100)\n","    eval_dl = DataLoader(eval_dt, batch_size=config['batch_size'], shuffle=True, pin_memory=True, drop_last=True)\n","    # build unseen test_dt\n","    test_dt = PAMAP2Dataset(data=data_dict['test']['X'], actions=data_dict['test']['y'], attributes=video_feat, attribute_dict=action_dict, action_classes=unseen_classes, seq_len=100)\n","    test_dl = DataLoader(test_dt, batch_size=config['batch_size'], shuffle=True, pin_memory=True, drop_last=True)\n","    \n","    # build model\n","    imu_config = {\n","        'in_ft':in_ft, \n","        'd_model':config['d_model'], \n","        'num_heads':config['num_heads'], \n","        'ft_size':config['feat_size'], \n","        'max_len':seq_len, \n","        'n_classes':len(seen_classes)\n","    }\n","    model = IMUEncoder(**imu_config)\n","    model.to(device)\n","\n","    # define run parameters \n","    optimizer = Adam(model.parameters(), lr=config['lr'], weight_decay=1e-5)\n","    loss_module = {'class': nn.CrossEntropyLoss(reduction=\"sum\"), 'feature': nn.L1Loss(reduction=\"sum\")}\n","    best_acc = 0.0\n","\n","    # train the model \n","    train_data = []\n","    for epoch in tqdm(range(config['n_epochs']), desc='Training Epoch', leave=False):\n","    \n","        train_metrics = train_step(model, train_dl, train_dt,optimizer, loss_module, device, class_names=[all_classes[i] for i in seen_classes], phase='train', loss_alpha=0.0001)\n","        train_metrics['epoch'] = epoch\n","        train_metrics['phase'] = 'train'\n","        train_data.append(train_metrics)\n","\n","        eval_metrics = eval_step(model, eval_dl, eval_dt,loss_module, device, class_names=[all_classes[i] for i in seen_classes], phase='seen', loss_alpha=0.0001, print_report=False)\n","        eval_metrics['epoch'] = epoch \n","        eval_metrics['phase'] = 'valid'\n","        train_data.append(eval_metrics)\n","        # print(f\"EPOCH [{epoch}] TRAINING : {train_metrics}\")\n","        # print(f\"EPOCH [{epoch}] EVAL : {eval_metrics}\")\n","        if eval_metrics['accuracy'] > best_acc:\n","            best_model = deepcopy(model.state_dict())\n","    \n","    train_df = pd.DataFrame().from_records(train_data)\n","    plot_curves(train_df)\n","\n","    # replace by best model \n","    model.load_state_dict(best_model)\n","    save_model(model,notebook_iden,model_iden,i)\n","\n","    # run evaluation on unseen classes\n","    test_metrics = eval_step(model, test_dl,test_dt, loss_module, device, class_names=[all_classes[i] for i in unseen_classes], phase='unseen', loss_alpha=0.0001, print_report=False)\n","    fold_metric_scores.append(test_metrics)\n","    print(test_metrics)\n","    print(\"=\"*40)\n","\n","print(\"=\"*14, \"Overall Unseen Classes Performance\", \"=\"*14)\n","seen_score_df = pd.DataFrame.from_records(fold_metric_scores)\n","seen_score_df.mean()\n"],"metadata":{"id":"ezbEvFA9IA_K","executionInfo":{"status":"aborted","timestamp":1678021547567,"user_tz":-330,"elapsed":19,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cpSPnALYIC-N","executionInfo":{"status":"aborted","timestamp":1678021547567,"user_tz":-330,"elapsed":19,"user":{"displayName":"Nipun Deelaka","userId":"13442159417355606895"}}},"execution_count":null,"outputs":[]}]}